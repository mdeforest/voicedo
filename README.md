# VoiceDo

A voice-first todo app for iOS, designed for people with ADHD and Autism. Press a button, speak your tasks naturally, and the app turns your words into organized, actionable tasks — no typing required.

Voice input is powered by Apple's on-device Speech framework. Natural language parsing (extracting tasks, dates, and lists from free-form speech) is handled by the Claude API.

## Stack

| Layer | Choice |
|-------|--------|
| Language | Swift 5.9+ |
| UI | SwiftUI + MVVM |
| Persistence | SwiftData |
| Voice | Apple Speech framework |
| Parsing | Claude API (Anthropic) |
| Notifications | UserNotifications |
| Networking | URLSession |
| Minimum iOS | 17.0 |

No third-party dependencies.

## Requirements

- Xcode 15+ (Xcode 16 recommended)
- iOS 17+ Simulator or device
- [xcodegen](https://github.com/yonaskolb/XcodeGen) — to regenerate the `.xcodeproj` after structural changes
- An [Anthropic API key](https://console.anthropic.com) (required for Phase 4 voice parsing)

Install xcodegen if you don't have it:

```bash
brew install xcodegen
```

## Getting Started

**1. Clone the repo**

```bash
git clone <repo-url>
cd voicedo
```

**2. Add your API key**

```bash
cp VoiceDo/Config.example.swift VoiceDo/Config.swift
```

Open `VoiceDo/Config.swift` and replace `YOUR_API_KEY_HERE` with your key from [console.anthropic.com](https://console.anthropic.com). This file is gitignored — never commit it.

**3. Generate the Xcode project**

```bash
xcodegen generate
```

**4. Open and run**

```bash
open VoiceDo.xcodeproj
```

Select an iOS 17+ simulator and hit **Run** (⌘R).

## Project Structure

```
voicedo/
├── VoiceDo.xcodeproj          Generated by xcodegen — don't edit directly
├── project.yml                xcodegen config — edit this, then re-run xcodegen generate
├── scripts/
│   └── sim-restart.sh         Boot or restart the iPhone 17 Pro Max simulator
└── VoiceDo/
    ├── App/                   Entry point, ModelContainer setup, Inbox seeding
    ├── Models/                SwiftData models: Task, TaskList
    ├── ViewModels/            HomeViewModel (@Observable)
    ├── Views/
    │   ├── Home/              List-of-lists screen
    │   ├── ListView/          Tasks within a list (Phase 2)
    │   ├── TaskDetail/        Single task view (Phase 2)
    │   ├── Voice/             Voice input overlay (Phase 3)
    │   ├── Settings/          Settings screen (Phase 6)
    │   └── Components/        Reusable UI components
    ├── Services/
    │   ├── ClaudeAPIService   Anthropic API client (Phase 4)
    │   ├── SpeechService      SFSpeechRecognizer wrapper (Phase 3)
    │   └── NotificationService  Local notifications (Phase 5)
    ├── Utilities/             Constants, extensions (Color+hex, Date helpers)
    ├── Resources/             Assets.xcassets (AppIcon, AccentColor)
    ├── Config.swift           Gitignored — holds ANTHROPIC_API_KEY
    ├── Config.example.swift   Safe template to commit
    └── Info.plist             Generated by xcodegen
```

## Build Phases

| Phase | Status | Description |
|-------|--------|-------------|
| 1 | ✅ Complete | Project setup, SwiftData models, app shell, Inbox seeding |
| 2 | ⬜ Pending | Task CRUD, list management, drag-to-reorder, nesting |
| 3 | ⬜ Pending | SpeechService, mic button, live transcript overlay |
| 4 | ⬜ Pending | Claude API integration, review cards, smart editing |
| 5 | ⬜ Pending | Reminders, local notifications |
| 6 | ⬜ Pending | UI polish, ADHD-friendly UX |
| 7 | ⬜ Pending | Accessibility audit, testing |
| 8 | ⬜ Pending | Deployment prep, TestFlight |

## Useful Commands

**Regenerate the Xcode project** (run after adding or removing files/folders):
```bash
xcodegen generate
```

**Boot or restart the iPhone 17 Pro Max simulator:**
```bash
./scripts/sim-restart.sh
```

## Data Model

**TaskList** — a named collection of tasks. The default `Inbox` is seeded on first launch and cannot be deleted or renamed.

**Task** — a single to-do item. Supports optional due dates, reminders, notes, and nested subtasks (up to 5 levels deep via a self-referential `parent`/`children` relationship).

## Configuration

`Config.swift` (gitignored) exposes one constant:

```swift
enum Config {
    static let anthropicAPIKey = "YOUR_API_KEY_HERE"
}
```

The Claude API is only called during Phase 4 voice parsing. The app is fully functional offline — voice recognition runs on-device and all data is stored locally via SwiftData.
